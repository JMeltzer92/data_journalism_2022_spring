---
title: "Class Reference"
author: "Student name"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Four (Typical) Data Types
Numeric = a number
Character = "text" like county or business name, but can also be numbers like ZIP codes of phone numbers; identifiers
Date = fully-formed dates, like 2019-10-01; incomplete dates, like 2019, are numberic
Logical = yes/no, true/false, etc; rare(ish)

## General

!Set Working Directory! - do this first
setwd("~target/path/name")

Use /# to make comments like <-- --> in HTML or /* */ in CSS

**FILTER > GROUP_BY > SUMMARIZE > ARRANGE** - general flow for R

Making a code block always looks like:
```{r}

```

ppp_maryland_loans <- read_rds("ppp_maryland.rds")
[        1       ][ 2 ][   3  ][        4        ]
*variable* [1] name used to refer to some more complex thing
*variable assignment operator* [2] assigns a word to something
*function* [3] computer code that takes in information; follows series of pre-determined steps; spits it back out
*argument* [4] things put inside of function to customize what the function does

*x ~ y* = if it's x, "then" change it to y
*^abc* = if it starts with "abc"
*%>%* = "and then do this"
*data %>% function* = typical pattern, "take data and do this specific action"

data %>% group_by(COLUMN NAME) %>% summarize(VARIABLE NAME = AGGREGATE FUNCTION(COLUMN NAME))

## Functions & Commands
*glimpse(x)* = list of the columns, the data type for each column, first few values for each column
*head(x)* = print out columns & first six rows of data
*head(x)* = first 6 rows of dataset x
*colnames (x)* = names of all columns in dataset x
*summary(x)* = for numerics: minimum, 1st quartile, median, mean, 3rd quartile, and max of all columns in dataset x; for characters: number of rows
*group_by(x)* = group data together by column "x" character
*select(x,y,z)* = show all rows but only with columns x, y and z
*summarise(x)* = sets up any desired summaries
  EXAMPLE:
  ppp_maryland_loans %>%               - take this data set;
  group_by(project_county_name) %>%    - group rows together according to the names of the counties;
  summarise(                           - and summarize it like this:
    count_loans = n()                  - the number of rows (each individual loan) in each county name.
  )
*get_dupes()* = check for duplicates in first column in dataset
*distinct()* = find all different valued entries in first column in dataset

*n()* = the number of the summarized function
*nrow(x)* = number of rows in dataset "x"
*arrange(x)* = arrange according to a certain property; can have multiple targets to sort by one than the other
  EXAMPLES:
  arrange(desc(count_loans))           - highest number number of loans first
  arrange(project_county_name,race)    - loans in each county to each racial demographic
alphabetically
  arrange(percent_payroll, desc(amount)) - lowest payroll percentage, and within that, highest loan amount - *first column in arrange takes precedent, then second, and so on*
    arrange(desc())                    - highest to lowest
    arrange()                          - lowest to highest
    -default-                          - alphabetically

*sum(x)* = sum of numeric values in column "x"
*mean(x)* = average of numeric values in column "x"
*median(x)* = value that sits at the midpoint of all values in column "x"
*min(x)/max(x)* = lowest/highest value in column "x"

*mutate(x = y)* = create new column "x" with a value (typically a function) of "y"
  mutate(percent_payroll = payroll_proceed/amount)*100 - find out what percent of each loan went towards payroll by dividing the raw amount sent to payroll by the total loan, and multiply by 100
  mutate(in_out = *if_else*(
    servicing_lender_state == 'MD', "IN", "OUT"
  ) = make new column "in_out" saying if s_l_s is or isn't in Maryland, remember double *==*
  maryland_jobs_categories <- maryland_ppp %>%
mutate(
  jobs_retained_category = *case_when*(
    jobs_retained < 10 ~ 'under_10',
    jobs_retained >= 10 & jobs_retained < 25 ~ '10_to_25',
    jobs_retained >= 50 & jobs_retained < 100 ~ '50_to_100',
    jobs_retained >= 100 & jobs_retained < 250 ~ '100_to_250',
    jobs_retained >= 250 & jobs_retained < 500 ~ '250_to_500',
    jobs_retained == 500 ~ '500'
  ) = new column based on ranges of values; similar to if_else but with >2 potential buckets
)
    (x = y ~ z) = If column x value is y, then change it to z
    str_detect(x, "^abc") ~ y = if value in column x starts with "abc" then change it to y
    TRUE ~ x = all other values in column x stay the same
  *across(x, as.y)* = change character type of column x to type y
    
  *CleanDate = ymd_hms(x)* - /lubridate only/ = parse dates more accurately without extra code - *read_csv* (instead of read_csv) also works; use *CleanDate = ymd(x)* if there's no time; MAKE SURE FILE EXTENSION MATCHES
  *floor_date(x, "y")* = rounds column "x" down to nearest boundary of specified time unit "y"
  *ceiling_date(x, "y")* = rounds column "x" up to nearest boundary of specified time unit "y"
  *str_to_upper/lower(x)* = change letters in of characters in column "x" to make all letters upper/lowercase
  *str_to_title(x)* = capitalize the first letter of every word
  *x=as.character(y)* = change data type of column x to a character with a value of y (can change value with formulas in "y" space); can also change to .numeric, .date, etc...
  *x = str_sub(x, start=yL, end=zL)* = change length of values in column X to start at Yth letter character from the left and end at Zth from the left; change to yR and zR to count from the right
  
*read_csv("y", guess_max=x* = use only x number of columns to try to guess the data type for each column in dataset y

*filter(x [y] z)*:  x = any column name from your dataframe; [y] = some comparison operator (==, >,  <); Z = something to compare the x to
  use /&/ to do more than one filter at once, e.g. <filter(project_county_name == "PRINCE GEORGES" & business_type == "Non-Profit Organization" & amount > 150000)>
  use /|/ to allow for more than one filter criteria, wherein a row that fits any one of the listed filters will be shown, e.g. <filter(project_county_name == "PRINCE GEORGES" | business_type == "Non-Profit Organization" | amount > 150000)>
  /Look at your data before you filter - names need to be EXACT, including capitalization, to be captured by filters/
  *is.na(x)* = filter all rows wherein column "x" value is NA; /this is the only way to target NA values, its not a number/
  
*clean_names()* = fixes the column headers in a dataset with janitor library
*rename(x = y)* = changes column header y to new header x

*bind_rows(list(x,y,z))* = combine datasets x, y and z to compare trends over time - must have exact same formatting
*x %>% left_join(y, by="z")* = join dataset x with datset y according to value in column z, while eliminating non-matching rows
  EXAMPLE
  maryland_ppp_with_naics %>% left_join(maryland_zcta, by=c("zip"="ZCTA5N"))
    merge ppp_with_naics with zcta, using different named columns zip and ZCTA5N
*x %>% right_join(y, by="z")* = join dataset x with dataset y according to values in column z, while still displaying rows that didnt have matching values


## Different Libraries ##

*lubridate* - for working with dates; "easier to do the things R does with date-times and possible to do the things R does not"
*tidyverse* - group of libraries that makes life easier
*janitor* - makes your data easier to work with my fixing abnormalities in headers and data types