---
title: "Reverse Engineering Project"
author: "Student names here"
date: "Date here"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

In this notebook, we are reverse engineering the story, [As police struggle to solve homicides, Baltimore residents see an ‘open season for killing’](https://www.washingtonpost.com/investigations/as-police-struggle-to-solve-homicides-baltimore-residents-see-an-open-season-for-killing/2018/12/26/7ee561e4-fb24-11e8-8c9a-860ce2a8148f_story.html)

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
```

## Load and Cleaning Data

In this section, describe the source of the data, write a basic data dictionary for data you are working with, and discuss any caveats or issues you discovered working with this data. 

```{r}
homicide_data <- read_csv('data/homicide-data.csv')

homicide_data <- homicide_data %>% 
  mutate(
    reported_date=as_date(ymd(reported_date))
  )

glimpse(homicide_data)

baltimore_homicide_data <- homicide_data %>% 
  filter (
    city == 'Baltimore'
  )

```

## Sentences to Engineer
In this notebook, we are reverse engineering five sentences from the story.

### Sentence 1

* **Sentence text**: City police made an arrest in 41 percent of homicides in 2014; last year, the rate was just 27 percent, a 14 percentage point drop.
* **Analysis summary**: After we successfully filtered and grouped the data in the years 2014 and 2017, we added all the murders up (112+86+13=211 for 2014, 236+93+11=340 for 2017), then divided the "Closed with Arrest" murders by the total murders for each year (86/211 and 93/340, respectively). This gave us a 40.75% arrest rate for 2014, and 27.35% for 2017. This correlates to a 14 percentage point drop, as they found in the original article. 

```{r}
baltimore_homicide_data %>% 
  filter (
    reported_date >= "2014-01-01" & 
    reported_date < "2015-01-01") %>% 
  group_by(disposition) %>% 
  summarize(
    count_murders=n()
  ) %>% 
  arrange(desc(count_murders))


baltimore_homicide_data %>% 
  filter (
    reported_date >= "2017-01-01" &
    reported_date < "2018-01-01"
  ) %>% 
  group_by(disposition) %>% 
  summarize(
    count_murders=n()
  ) %>% 
  arrange(desc(count_murders))

```

### Sentence 2

* **Sentence text**: As violence in the city has risen since 2015, the likelihood of a killer being arrested has dropped precipitously.
* **Analysis summary**: We do see the Post's results replicated by our code. The number of arrests categorized as "Open" or "Closed without arrest" jumps sharply in 2015 and stays high through the end of 2017.

```{r}
baltimore_homicides_by_year <- baltimore_homicide_data %>% 
  mutate(
    year = year(reported_date))

baltimore_yearly_arrest_rate <- baltimore_homicides_by_year %>% 
  group_by(year,disposition) %>% 
  summarize(
    count_homicides=n()
  )

show(baltimore_yearly_arrest_rate)
```

### Sentence 3

* **Sentence text**: Of the 1,002 homicides between 2015 and the beginning of this year, just 252 — one out of every four — resulted in an arrest.
* **Analysis summary**: We were able to replicate the Post's findings for this. Of all the homicides reported after 2018, our filter and group by queries showed that there were 252 closed by arrest out of a total of 1002. It's not exactly 1 in 4, but it's close.

```{r}
baltimore_homicide_data %>% 
  filter(
    reported_date > '2015-01-01'
  ) %>% 
  group_by(disposition) %>% 
  summarize(
    count_homicides=n()
  ) %>% 
    arrange(count_homicides)
```

### Sentence 4

* **Sentence text**: For most of the decade before 2015, Baltimore’s annual homicide arrest rate hovered at about 40 percent. Since 2015, the arrest rate hasn’t topped 30 percent in any year
* **Analysis summary**: We were able to find the same results as the Washington Post. The homicide arrest rate, or homicides "closed by arrest" divided by total homicides for each year, did hover around 40% from 2005 to 2015, and then stays below 30% after 2015.

```{r}
baltimore_yearly_homicides <- baltimore_homicides_by_year %>% 
  group_by(year) %>% 
  summarize(
    count_homicides=n()
  )

baltimore_rate <- baltimore_yearly_arrest_rate %>% 
  left_join(baltimore_yearly_homicides, by="year") %>% 
  filter(
    disposition == "Closed by arrest"
  ) %>% 
  mutate(
    rate=(count_homicides.x/count_homicides.y)*100
  )
```

### Sentence 5

* **Sentence text**: Baltimore is also one of 30 cities that have seen an increase in homicides in recent years, with the greatest raw number increase in killings of any city other than Chicago, which has four times the population.
* **Analysis summary**: We used ggplot on all of the cities in our dataframe to make sure there was indication of an increase in total homicides across the country, which there is for 30 of the line segments shown. This is where it gets tricky: the language the Post uses is inexact. "The greatest raw number increase in killings" since when? Our data shows both Baltimore and Chicago total murders soaring in the 2014-2016 period, but other cities among the 30 have homicides increase at different times and at different rates. While we wouldn't call this disingenuous, it does seem that the journalists chose somewhat vague language instead painting an exact picture, which, in their defense, may have been very wordy.

```{r}
homicide_by_city <- homicide_data %>%
    mutate(
      year = year(reported_date),
      city = gsub("\\s", "_", tolower(city))
    ) %>%
  group_by(city, year) %>% 
  summarise(total_homicides=n())
```
## Try Pivoting
```{r}
is_it_on <- homicide_by_city %>% 
  pivot_wider(names_from = city, values_from = total_homicides) %>% 
  arrange(desc(year))
```

## Line Plot

```{r}
homicide_by_city %>% 
  ggplot(aes(x=year, y=total_homicides, color=city)) + geom_line() + geom_point()
```